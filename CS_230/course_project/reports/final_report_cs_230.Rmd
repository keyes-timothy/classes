---
title: "Final Report - Using deep autoencoder feature embeddings to explore single-cell phenotypes in pediatric cancer"
author: "Timothy Keyes"
output: pdf_document
fontsize: 11pt 
geometry: margin = 0.45in
urlcolor: blue

---

```{r setup, include=FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r message=FALSE, warning=FALSE}
# Libraries
library(tidyverse)
library(rlang)
library(reticulate)
library(ggridges)
library(kableExtra)

# Parameters

data_path <- here::here("CS_230", "course_project", "data")
big_data_path <- here::here("CS_230", "course_project", "data", "DDPR_data.rds")
saucie_data_path <- here::here("CS_230", "course_project", "data", "sampled_DDPR_data.rds")
saucie_output_path <- here::here("CS_230", "course_project", "data", "saucie_output.csv")
classifier_data_path <- here::here("CS_230", "course_project", "data", "classifier_saucie_result.rds")
plot_out_path <- here::here("CS230", "course_project", "eda")

metadata <- c("patient")

CLASSIFIER_POPULATIONS <-
  c(
    "HSC", 
    "Progenitor_1", 
    "Progenitor_2", 
    "Progenitor_3", 
    "Pre_Pro_B", 
    "Pro_B1", 
    "Pro_B2", 
    "Pre_B1", 
    "Pre_B2", 
    "Early_Progenitors", 
    "Late_Progenitors", 
    "Immature_B1", 
    "Immature_B2", 
    "Mature_B", 
    "Mature_Non_B"
  )

MARKERS <- 
  c(
    'CD19', 
    'CD20', 
    'CD34', 
    'CD38', 
    'IgMi', 
    'IgMs', 
    'CD179a', 
    'CD179b',
    'CD127', 
    'Tdt',
    'CD45', 
    'PLCg2', 
    'CD22', 
    'p4EBP1', 
    'Ikaros', 
    'CD79b', 
    'pSTAT5',
    'CD123',
    'Ki67', 
    'IgL kappa',
    'IKAROS_i', 
    'CD10', 
    'pAkt',
    'CD24', 
    'CRLF2', 
    'RAG1', 
    'Pax5',
    'pSyk',
    'CD43',
    'CD58',
    'HIT3a',
    'CD16',
    'pS6',
    'pErk',
    'HLADR',
    'pCreb'  
  )

overexpressed_markers <-
  c(
    'PLCg2', 
    'CD22', 
    'p4EBP1', 
    'Ikaros', 
    'CD79b', 
    'pSTAT5',
    'CD123',
    'IKAROS_i', 
    'pAkt',
    'CRLF2', 
    'Pax5',
    'pSyk',
    'HIT3a',
    'pS6',
    'pErk',
    'pCreb'  
  )


#===============================================================================

```


```{r, message = FALSE, warning = FALSE}
# read in big data 
big_data <- 
  big_data_path %>% 
  read_rds()

#read in data

#read in classified data 
classifier_output <- 
  classifier_data_path %>% 
  read_rds() %>% 
  group_by(classified_population) %>% 
  sample_n(size = 10000, replace = TRUE) %>% 
  ungroup()

saucie_data <-
  classifier_output

#save data as .csv for SAUCIE
# saucie_data %>% 
#   ungroup() %>% 
#   select(one_of(MARKERS)) %>% 
#   transmute_all(scale) %>% 
#   write_csv(path = file.path(data_path, "saucie_data.csv"), col_names = TRUE)
```

```{r, eval = FALSE}
#read in data from saucie clustering
saucie_output <- 
  saucie_output_path %>% 
  read_csv() %>% 
  select(-X1)
```


```{r}
#retrieve saucie output files
saucie_paths <- 
  list.files(data_path, pattern = "*saucie_output_\\d", full.names = TRUE)

all_saucie_outputs <- 
  tibble(file_names = saucie_paths) %>% 
  mutate(
    lambda_c = 
      str_split(file_names, pattern = "_") %>% 
      map_chr(function(x) x[[5]]), 
    lambda_d = 
      str_split(file_names, pattern = "_") %>% 
      map_chr(function(x) x[[6]]) %>% 
      str_sub(end = -5L), 
    overall_F = 0, 
    num_clusters = 0
  )

```

```{r, message = FALSE, warning = FALSE}
for (i in 1:nrow(all_saucie_outputs)) { 
  saucie_output <- 
  saucie_paths[[i]] %>% 
  read_csv() %>% 
  select(-X1)
  
  match_matrix <- 
    bind_cols(classifier_output, saucie_output) %>% 
    unique() %>% 
    transmute(
      developmental_cluster = classified_population, 
      saucie_cluster = as.factor(clusters)
    ) %>% 
    filter(saucie_cluster != -1) %>% 
    count(developmental_cluster, saucie_cluster)
  
  developmental_totals <- 
    classifier_output %>% 
    unique() %>% 
    select(developmental_cluster = classified_population) %>% 
    count(developmental_cluster)
  
  saucie_totals <- 
    saucie_output %>% 
    dplyr::transmute(saucie_cluster = as.factor(clusters)) %>% 
    filter(saucie_cluster != -1) %>% 
    count(saucie_cluster)
  
  final_F <- 
    match_matrix %>% 
    group_by(developmental_cluster) %>% 
    mutate(recall = n / sum(n)) %>% 
    group_by(saucie_cluster) %>% 
    mutate(precision = n / sum(n)) %>% 
    ungroup() %>%
    mutate(F_measure = (2 * precision * recall) / (precision + recall)) %>% 
    group_by(developmental_cluster) %>% 
    filter(F_measure == max(F_measure)) %>% 
    ungroup() %>% 
    left_join(saucie_totals) %>% 
    rename(saucie_total = n) %>% 
    left_join(developmental_totals) %>% 
    rename(developmental_total = n) %>% 
    transmute(F_measure = F_measure * developmental_total / sum(developmental_total)) %>% 
    summarize(final_F = sum(F_measure)) %>% 
    pull(final_F)
  
  all_saucie_outputs$overall_F[[i]] <- final_F
  all_saucie_outputs$num_clusters[[i]] <- length(unique(saucie_output$clusters)) - 1
}

winning_path <- 
  all_saucie_outputs %>% 
  dplyr::filter(lambda_c != "0.0", lambda_d != "0.0") %>% 
  arrange(desc(overall_F)) %>% 
  slice(1) %>% 
  pull(file_names)
```


```{r, message = FALSE, warning = FALSE}
saucie_output <- 
  winning_path %>% 
  read_csv() %>% 
  select(-X1)

match_matrix <- 
  bind_cols(classifier_output, saucie_output) %>% 
  unique() %>% 
  transmute(
    developmental_cluster = classified_population, 
    saucie_cluster = as.factor(clusters)
  ) %>% 
  filter(saucie_cluster != -1) %>% 
  count(developmental_cluster, saucie_cluster)

developmental_totals <- 
  classifier_output %>% 
  unique() %>% 
  select(developmental_cluster = classified_population) %>% 
  count(developmental_cluster)

saucie_totals <- 
  saucie_output %>% 
  dplyr::transmute(saucie_cluster = as.factor(clusters)) %>% 
  filter(saucie_cluster != -1) %>% 
  count(saucie_cluster)

precision_recall_table <- 
  match_matrix %>% 
  group_by(developmental_cluster) %>% 
  mutate(recall = n / sum(n)) %>% 
  group_by(saucie_cluster) %>% 
  mutate(precision = n / sum(n)) %>% 
  ungroup() %>%
  mutate(F_measure = (2 * precision * recall) / (precision + recall)) %>% 
  group_by(developmental_cluster) %>% 
  filter(F_measure == max(F_measure)) %>% 
  ungroup() %>% 
  transmute(
    `Developmental Population` = developmental_cluster, 
    Precision = precision, 
    Recall = recall, 
    `F-measure` = F_measure
  ) %>% 
  arrange(desc(`F-measure`))

final_F <- 
  match_matrix %>% 
  group_by(developmental_cluster) %>% 
  mutate(recall = n / sum(n)) %>% 
  group_by(saucie_cluster) %>% 
  mutate(precision = n / sum(n)) %>% 
  ungroup() %>%
  mutate(F_measure = (2 * precision * recall) / (precision + recall)) %>% 
  group_by(developmental_cluster) %>% 
  filter(F_measure == max(F_measure)) %>% 
  ungroup() %>% 
  left_join(saucie_totals) %>% 
  rename(saucie_total = n) %>% 
  left_join(developmental_totals) %>% 
  rename(developmental_total = n) %>% 
  transmute(F_measure = F_measure * developmental_total / sum(developmental_total)) %>% 
  summarize(final_F = sum(F_measure)) %>% 
  pull(final_F)
```

# Abstract

Single-cell data are collected in both research and clinical laboratories in order to evaluate leukemia patients' blood samples for the presence of various cell types. Specifically, the enumeration of various developmental "blast" types within leukemic samples is often of clinical and research interest. However, state-of-the-art methods for measuring cells' biological characteristics are prone to batch effects and other forms of noise due to differences in individual laboratories' instrumentation, operators, and on-hand reagents. Here, we adapt a previously-published, multi-tasking autoencoder called "SAUCIE" (Sparse Autoencoder for Unsupervised Clustering, Imputation, and Embedding) to denoise, cluster, and visualize single-cell data from human blood samples taken from B-cell Precursor Acute Lymphoblastic Leukemia (BCP-ALL) patients. We evaluate the performance of the algorithm compared to a gold-standard, supervised clustering algorithm developed specifically for BCP-ALL data and investigate its population-specific performance.  

# 1 - Introduction

## Problem importance and motivation

In the clinical evaluation of leukemia (blood cancer), most diagnostic and prognostic tests rely on the identification and enumeration of leukemic "blasts" in the blood and bone marrow of patients. Blasts are immature blood cells that - due to genetic and epigenetic abnormalities - develop aberrancies in cellular maturation that cause them to become cancerous. Blast phenotypes differ widely between patients both because of individual differences in the biology of each patient's cancer and because of instrumentation differences between clinics where testing is conducted. This means that the current gold standard of diagnostic and prognostic testing for leukemia relies on pathologists manually inspecting the protein-level phenotypes of cancer patients by eye using [microscopy](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7065280/),^1^ and [flow cytometry](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4729109/).^2^ 

Here we use deep learning to take a step towards automating methods of enumerating leukemic blasts by building an autoencoder framework capable of denoising, batch-correcting, and clustering protein-level data collected by single-cell cytometry such that individual differences in protein marker expression are preserved but instrument-to-instrument differences are reduced. We also use this multi-tasking autoencoder to extract clustering information from one layer of the network for the unbiased indentification of blast-like cells within the denoised feature space. 

## Input and Output

The input for this algorithm is a `.fcs` file^3^ (or folder of `.fcs` files) containing single-cell information collected via a flow cytometer or a mass cytometer, two types of instrument that collect protein-level features from individual cells.^2^ The data represented in an .fcs file can be represented as an [m x n] matrix in which `m` represents the number of cells that you've measured and `n` represents the number of proteins that you've measured within each cell. 

The output of the algorithm includes the following: 

1. A reconstructed `n`-dimensional feature-vector for each cell after being passed through the autoencoder.

1. A label for each cell indicating which cluster it was assigned to by the decoder of the network (see methods below). The clusters are identified in an unsupervised manner and the number of clusters is automatically detected by the network. 

# 2 - Related Work

Only a small amount of previous work has applyied deep learning to single-cell data, and an especially small amount of work has applied deep learning to flow or mass cytometry data. Specifically, 3 algorithms have been previously published that apply deep learning to single-cell cytometry data: DeepCyTOF,^4^ CellCNN,^5^ and SAUCIE.^6^ Details about each of these algorithms are provided below.

*DeepCyTOF* is a feed-forward neural network that automates the task of "gating" immune cell populations, a process whereby immunologists identify cell populations of interest manually by sequentially applying two-dimensional, hand-drawn filters to single-cell data.^4^ DeepCyTOF was the first deep learning algorithm applied to mass cytometry data, and was built as a depth-4 fully-connected network with softplus hidden units (except for the output layer, which was a softmax layer). Layer sizes were 12, 6, 3, and 1, respectively and were trained with RMSprop on a training set of blood samples taken from 14 patients infected with West Nile Virus. Importantly, DeepCyTOF was developed in order to identify distinct immune cell populations (which are known to differ widely from one another) and has not been tested on leukemic cell types.  

*CellCNN* (which stands for "Cellular Convolutional Neural Network") is a convolutional neural network approach to identifying cellular subtypes within a sample that associate with a particular clinical outcome of interest.^5^ In short, CellCNN works by applying 1-3 m-dimensional filters to each cell in the training set (where `m` is the number of proteins measured in each cell). The convolutional layer is followed by either a max pooling or average pooling layer, allowing the algorithm to identify the 1-3 major phenotypes associated with the clinical outcome on a single-cell level. The strengths of CellCNN include that it is able to identify relatively rare cell types that associate with clinical outcomes while ignoring cell types that aren't associated with the outcome-of-interest. However, a weakness of CellCNN is that it doesn't perform any denoising or batch correction, which prevents it from being a fully end-to-end approach even when samples are clinically annotated.

This project leans heavily on existing implementations of a network method called *SAUCIE* developed using non-cancer cells and that we have adapted for this project.^6^ SAUCIE ("sparse autoencoder for unsupervised clustering, imputation, and embedding") is a multitasking autoencoder that "extends" the architecture of a simple autoencoder. It does so by adding several layers that are regularized in such a way that their outputs are biologically meaningful. These layers include a clustering layer that is regularized to penalize within-cluster distances between cells *and* that performs information dimension (ID) regularization (to encourage cluster sparsity); in addition, the "embedding" layer of the autoencoder (i.e. the middle layer between the encoder and the decoder) is regularized such that the pairwise distances between cells from different batches is minimized, allowing for denoising and batch correction. Details of the SAUCIE network are described below.

# 3 - Dataset and Features 

In this project, I am working with data originally published in a previous paper from my lab.^7^ The paper devised a method of "aligning" cancer cells with the healthy cell type with which they are most similar. Overall, the main idea of this paper was that comparing cancer cell subtypes to healthy cell subtypes might help us to infer how cancer cells behave or where they come from, and its main contribution to the field was a gold-standard clustering algorithm (called the "developmental classifier") that serves as a gold-standard method of annotating cancer cell types into their most biologically-interpretable cellular subpopulation. Specifically, the dataset obtained during this study included mass cytometry data from 60 patients with B-cell precursor acute lymphoblastic leukemia (BCP-ALL) and 5 healthy control patients.^8^

## Basic dataset characteristics

For this project, I worked with a cleaned version of these data to eliminate some of the frustration of working with samples that vary significantly in size and quality. Specifically, I limited the dataset to solely diagnostic specimens taken from the blood or bone marrow, and I sampled 10,000 cells from each unique cell subpopulation identified by the developmental classification algorithm described above. All patients that did not have at least 10,000 cells total in their sample were removed from the analysis. Information regarding the number of cells and basic summary statistics of the dataset are provided in the Appendix (*Table 1* and *Table 2*).

## Pre-processing

Data pre-processing was performed as is standard for CyTOF data analysis.^9^ Specifically, the following steps were performed: 1) All measurement values ("ion counts") taken from the cytometry were arsinh-transformed with a cofactor of 5 such that $final\ value = arcsinh(\frac{counts}{5})$. 2) Mass cytometers are prone to artefacts on both the upper- and lower- ends of their dynamic range. Thus, protein measurement values at or below the 1st percentile and at or above the 99th percentile of the measured ranges were excluded as outliers. 3) Protein expression values for remaining cells were centered and scaled such that each protein (each feature) had a mean of 0 and standard deviation of 1.  

## Example inputs

A single-cell feature vector in the input will look like this: 

```{r}
saucie_data %>% 
  select(one_of(MARKERS)) %>% 
  mutate_all(~ scale(.) %>% round(2)) %>% 
  slice(1) %>%
  knitr::kable()
```

Each cell is associated with 36 protein markers, each of which will provide 1 value in the cell's feature vector. Likewise, each cell population (of which there are 15 according to the gold-standard), will be associated with a distribution of marker expression levels for each protein. An example of what the distributions for two cell populations looks like relative to one another is provided in the Appendix (*Figure S2*). 

# 4 - Methods 

### Description of Network Architecture 

SAUCIE is a multitasking autoencoder that has 3 encoding layers, 1 embedding layer, and three decoding layers, all of which are fully-connected. The number of neurons per hidden layer in the encoder were 512, 256, and 128 with a symmetric decoder; the embedding layer had 2 neurons. The embedding layer used a linear activation function; all other layers used a leaky rectified linear unit activation with leak = 0.2 function except the final layer of the decoder (the layer responsible for performing clustering), which used a rectified linear unit (without leak). Batches of size 300 were used for 1000 steps (in order to train on the entire dataset for 20 epochs). The optimization was performed with ADAM and a learning rate of 0.001. 

### Loss function 

Our adaptation of SAUCIE has 3 components to its loss function. The first component is the simple reconstruction penalty present in any autoencoder, for which we used the mean-squared error of the output representation and the original input data. If we consider the following quantities...

* $x_i$ = the input feature vector of the ith cell in the dataset
* $\hat x_i$ = the output feature vector of the ith cell in the dataset
* $m$ = the number of cells in the input dataset, 

Then the loss term from the reconstruction is given by the following: 

$$
L_{reconstruction} = \frac{1}{m}\sum_i^m(x_i - \hat x_i)^2
$$

The other two components of the loss function are derived from the "clustering" layer (the second-to-last decoding layer), which performs two (opposing) kinds of regularization. The first regularization penality in this layer is an interformation dimension (ID) regularization that encourages activations of the neurons in the layer to be binarized such that sparser representations (i.e. representations with fewer clusters) are penalized less. Thus, the ID regularization term (applied to the clustering layer) is given by 

$$ 
L_{ID} = -\sum_{i = 1}^kp_ilog(p_i)
$$

where $k$ is the number of neurons in the clustering layer and $p_i$ normalized activation of the ith neuron in the clustering layer $a_i$ such that $p_i = \frac{a_i}{||a_i||_1}$.

Finally, the last component of the loss function is a penalty on intracluster distances for the clusters in the clustering layer of the network, which is calculated as the Euclidian distance between points that are located in the same cluster (in the denoised output space): 

$$
L_{cluster\ distances} = \sum_{i, j}||\hat x_i - \hat x_j||^2
$$

for all cells i, j assigned to the same cluster by the network. Thus, while $L_{ID}$ is minimized by assigning all cells to the same cluster, $L_{cluster\ distances}$ acts as an opposing balance, as it will be minimized only if each cell were placed in a cluster by itself. 

Thus, the total loss function is given by $L_{total} = L_{reconstruction} + \lambda_c * L_{ID} + \lambda_d * L_{cluster\ distances}$, where $\lambda_c$ and $\lambda_d$ are tuning parameters that weight the degree that the ID regularization and the intracluster distance penalty will affect the clusteringl layer. In our implementation, we tuned these hyperparameters by performing a grid search over the values 0-1 at 0.1 intervals and selecting the combination with optimal performance. 

# 5 - Experiments/Results/Discussion

### Hyperparameter tuning

Default values for the number of neurons to use in each layer were used, by the hyperparameters $\lambda_c$ and $\lambda_d$ were tuned by calculating each result's performance using a previously-validated metric for analyzing clustering results with single-cell cytometry data.^10^ Specifically, because SAUCIE is an unsupervised learning algorithm, we evaluated its performance by comparing it to the "gold-standard" supervised clustering algorithm that the authors applied to the same data in the original paper for which the data were collected. Specifically, we compared SAUCIE's performance to the original authors' algorithm using a version of the F1-measure of classification accuracy commonly used to compare single-cell clustering methods to one another. In short, the F1-measure is the harmonic mean of precision and recall for classification compared to a gold-standard method. SAUCIE performed with an F1-measure overall of `r final_F %>% round(2)`, making it slightly less than average as far as clustering algorithms applied to mass cytometry datasets are concerned. 

Population-specific performance is shown here: 

```{r}
precision_recall_table %>% 
  knitr::kable() %>% 
  kable_styling(font_size = 8)
```

### Embedding

If we look at the values for each cell in the embedding dimension of the autoencoder, we can see that the embedding doesn't seem to partition the gold-standard clusters from each other very well, but it does partition the clusters identified by the network itself quite well...

```{r, fig.height = 4, fig.width = 8}
classifier_plot <- 
  saucie_output %>% 
  bind_cols(classifier_output) %>% 
  mutate(
    classifier_cluster = classified_population, 
    saucie_cluster = clusters
  ) %>% 
  mutate(clusters = as.factor(clusters)) %>% 
  group_by(clusters) %>% 
  sample_n(size = 2000, replace = TRUE) %>%
  unique() %>% 
  ggplot(aes(x = embedding_1, y = embedding_2, color = classifier_cluster)) + 
  geom_point(alpha = 0.8) +
  labs(
    title = "Gold-standard clusters",
    x = "Embedding dimension 1", 
    y = "Embedding dimension 2"
  )

saucie_plot <- 
  saucie_output %>% 
  bind_cols(classifier_output) %>% 
  mutate(
    classifier_cluster = classified_population, 
    saucie_cluster = clusters
  ) %>% 
  filter(saucie_cluster != -1) %>% 
  mutate(saucie_cluster = as.factor(saucie_cluster)) %>% 
  group_by(clusters) %>% 
  sample_n(size = 2000, replace = TRUE) %>%
  unique() %>% 
  ggplot(aes(x = embedding_1, y = embedding_2, color = saucie_cluster)) + 
  geom_point(alpha = 0.8) +
  labs(
    title = "Network-identified clusters",
    x = "Embedding dimension 1", 
    y = "Embedding dimension 2"
  )

gridExtra::grid.arrange(classifier_plot, saucie_plot, ncol = 2)
```

These plots suggest that one way to improve the performance of the unsupervised clustering might be to include more neurons in the embedding dimension (as whatever mapping is being performed by the gold-standard categorizations may not be captured well in just 2 dimensions). 

# 6 - Conclusions/Future Work

In general, our algorithm was not particularly well-performing compared to the gold-standard. This is probably because the clusters that SAUCIE learns to identify are the ones that allow the best reconstruction of the input data (in our case, the input 36-dimensions) and not necessarily the clusters with the most biological interpretability (which is what the gold-standard algorithm is meant to represent). This may indicate that that a purely unsupervised approch to cluster identification may not be the best strategy for detecting rare cell types of a particular developmental origin. 

In future iterations of this project, I would be interested in combining the autoencoder that I experimented with here and some of the supervised approaches that have been used in either CellCNN (to incorporate a component of the loss function that is associated with a clinical outcome) or DeepCyTOF (to incorporate a component of the loss function based on having direct access to the class label for each cell).

# 7 - Contributions

I was the only team member for this project, so I performed all analyses myself.

# References

1. Abou Dalle I, Jabbour E, Short NJ. Evaluation and management of measurable residual disease in acute lymphoblastic leukemia. Ther Adv Hematol. 2020;11:2040620720910023. Published 2020 Mar 6. doi:10.1177/2040620720910023

2. Wang XM. Advances and issues in flow cytometric detection of immunophenotypic changes and genomic rearrangements in acute pediatric leukemia. Transl Pediatr. 2014;3(2):149‐155. doi:10.3978/j.issn.2224-4336.2014.03.06

3. https://en.wikipedia.org/wiki/Flow_Cytometry_Standard

4. Li H, Shaham U, Stanton KP, Yao Y, Montgomery RR, Kluger Y. Gating mass cytometry data by deep learning. Bioinformatics. 2017;33(21):3423‐3430. doi:10.1093/bioinformatics/btx448 

5. Arvaniti, E., Claassen, M. Sensitive detection of rare disease-associated cell subsets via representation learning. Nat Commun 8, 14825 (2017). https://doi.org/10.1038/ncomms14825

6. Amodio, M., van Dijk, D., Srinivasan, K. et al. Exploring single-cell data with deep multitasking neural networks. Nat Methods 16, 1139–1145 (2019). https://doi.org/10.1038/s41592-019-0576-7

7. Good Z, Sarno J, Jager A, et al. Single-cell developmental classification of B cell precursor acute lymphoblastic leukemia at diagnosis reveals predictors of relapse. Nat Med. 2018;24(4):474‐483. doi:10.1038/nm.4505

8. Finck R, Simonds EF, Jager A, et al. Normalization of mass cytometry data with bead standards. Cytometry A. 2013;83(5):483‐494. doi:10.1002/cyto.a.22271

9. Olsen LR, Leipold MD, Pedersen CB, Maecker HT. The anatomy of single cell mass cytometry data. Cytometry A. 2019;95(2):156‐172. doi:10.1002/cyto.a.23621

10. Aghaeepour, N., Finak, G., Hoos, H. et al. Critical assessment of automated flow cytometry data analysis techniques. Nat Methods 10, 228–238 (2013). https://doi.org/10.1038/nmeth.2365


# Appendix

### Table 1 - Summary table of patient cell counts

```{r}
big_data %>% 
  ungroup() %>% 
  count(patient, name = "Number of cells") %>% 
  knitr::kable() %>% 
  kable_styling(font_size = 8)
```


### Table 2 - Summary statistics for the dataset 

```{r, echo = FALSE, include = TRUE}
big_data %>% 
  ungroup() %>% 
  filter(stimulation == "basal") %>% 
  select(-file_name, -stimulation, -time) %>% 
  summary()
```

Most important to note here is that, as is common with mass cytometry data (particularly in cancer), the distributions are highly skewed such that there are often huge(!) outliers in the positive direction due to instrumentation failure. These values are not biologically informative, so filtering out all measurements that are above the 95th percentile in a given channel was performed.

### Figure S1 - Example marker distributions
```{r, warning = FALSE, message = FALSE, fig.height = 4}
classifier_output %>% 
  dplyr::filter(classified_population == "Mature_B" | classified_population == "Pre_B2") %>% 
  select(classified_population, CD24, CD34, IKAROS_i, CD123, Tdt, Ki67, CD45, CD38, IgMs, CD179b) %>% 
  mutate_at(vars(one_of(MARKERS)), ~ scale(.) %>% round(2)) %>% 
  pivot_longer(
    cols = one_of(MARKERS), 
    names_to = "marker", 
    values_to = "expression"
  ) %>% 
  group_by(marker) %>% 
  dplyr::filter(expression < 3, expression > -3) %>% 
  ungroup() %>% 
  mutate(
    marker = fct_reorder(marker, expression)
  ) %>% 
  ggplot(aes(x = expression, y = marker, fill = classified_population)) + 
  geom_density_ridges(alpha = 0.5, scale = 1.2)
```

Density plots for two gold-standard cell populations are provided above for several example protein markers in the dataset. Notably, features can differ between cell populations both in their central tendency and dispersion, and some markers will be more/less similar than others across multiple cell populations. 
